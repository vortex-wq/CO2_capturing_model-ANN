# -*- coding: utf-8 -*-
"""UG_PROJECT_CODE_FILE_ORIGINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cv55D_IKwyghEIGc_JJKlztM28OiiKzW
"""

# ============================================================
# COâ‚‚ Capture ANN Model (based on Journal of Cleaner Production, 2025)
# Train two models: ANN-PCO2 and ANN-qabs using TensorFlow
# ============================================================

# --- STEP 1. Install dependencies ---
!pip install tensorflow pandas scikit-learn matplotlib

# --- STEP 2. Import required libraries ---
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.initializers import HeNormal
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# --- STEP 3. Upload your dataset ---
from google.colab import files
uploaded = files.upload()

filename = list(uploaded.keys())[0]
data = pd.read_csv(filename)
print("Data loaded successfully:", filename)
print(data.head())

# --- STEP 4. Prepare features and targets ---
X = data[['Temperature_K', 'Blending_ratio_wt_percent', 'Alpha_mol_CO2_per_mol_amine']].values
y_pco2 = data['PCO2_kPa'].values
y_qabs = data['qabs_kJ_per_mol_CO2'].values

# --- STEP 5. Normalize input data (Z-score) ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_pco2_train, y_pco2_test = train_test_split(X_scaled, y_pco2, test_size=0.15, random_state=42)
_, _, y_qabs_train, y_qabs_test = train_test_split(X_scaled, y_qabs, test_size=0.15, random_state=42)

# --- STEP 6. Define custom loss functions ---
def smape_loss(y_true, y_pred):
    epsilon = 1e-6
    return tf.reduce_mean(100 * tf.abs(y_pred - y_true) / (tf.abs(y_true) + tf.abs(y_pred) + epsilon) / 2)

def combined_loss(y_true, y_pred):
    mse = tf.reduce_mean(tf.square(y_pred - y_true))
    return mse + smape_loss(y_true, y_pred)

def build_ann():
    model = Sequential([
        Dense(64, activation='sigmoid', kernel_initializer=HeNormal(), input_shape=(3,)),
        Dense(64, activation='sigmoid', kernel_initializer=HeNormal()),
        Dense(32, activation='sigmoid', kernel_initializer=HeNormal()),
        Dense(16, activation='sigmoid', kernel_initializer=HeNormal()),
        Dense(8, activation='sigmoid', kernel_initializer=HeNormal()),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss=combined_loss, metrics=['mse'])
    return model

# --- STEP 8. Train ANN for PCO2 ---
print("Training ANN for PCO2 prediction...")
model_pco2 = build_ann()
history_pco2 = model_pco2.fit(
    X_train, y_pco2_train, epochs=300, batch_size=16,
    validation_split=0.2, verbose=1,
    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)]
)

# --- STEP 9. Train ANN for qabs ---
print("Training ANN for qabs prediction...")
model_qabs = build_ann()
history_qabs = model_qabs.fit(
    X_train, y_qabs_train, epochs=300, batch_size=16,
    validation_split=0.2, verbose=1,
    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)]
)

# --- STEP 10. Evaluate both models ---
eval_pco2 = model_pco2.evaluate(X_test, y_pco2_test, verbose=0)
eval_qabs = model_qabs.evaluate(X_test, y_qabs_test, verbose=0)
print(f" ANN-PCO2 Test MSE: {eval_pco2[1]:.4f}")
print(f" ANN-qabs Test MSE: {eval_qabs[1]:.4f}")

# --- STEP 11. Plot training curves ---
def plot_history(history, title):
    plt.figure(figsize=(6,4))
    plt.plot(history.history['loss'], label='Train loss')
    plt.plot(history.history['val_loss'], label='Validation loss')
    plt.title(title)
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    plt.show()


plot_history(history_pco2, 'Training Curve: ANN-PCO2')
plot_history(history_qabs, 'Training Curve: ANN-qabs')

# --- Evaluate & Predict ---

# Define SMAPE metric for evaluation
def smape(y_true, y_pred):
    return np.mean(100 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-6) / 2)

# PCO2
y_pco2_pred = model_pco2.predict(X_test).flatten()
mse_pco2 = mean_squared_error(y_pco2_test, y_pco2_pred)
r2_pco2 = r2_score(y_pco2_test, y_pco2_pred)
smape_pco2 = smape(y_pco2_test, y_pco2_pred)

# qabs
y_qabs_pred = model_qabs.predict(X_test).flatten()
mse_qabs = mean_squared_error(y_qabs_test, y_qabs_pred)
r2_qabs = r2_score(y_qabs_test, y_qabs_pred)
smape_qabs = smape(y_qabs_test, y_qabs_pred)

print("\n Model Performance:")
print(f"ANN-PCO2  â†’ MSE: {mse_pco2:.3f}, RÂ²: {r2_pco2:.3f}, SMAPE: {smape_pco2:.3f}")
print(f"ANN-qabs  â†’ MSE: {mse_qabs:.3f}, RÂ²: {r2_qabs:.3f}, SMAPE: {smape_qabs:.3f}")

# PCO2
y_pco2_pred = model_pco2.predict(X_test).flatten()
mse_pco2 = mean_squared_error(y_pco2_test, y_pco2_pred)
r2_pco2 = r2_score(y_pco2_test, y_pco2_pred)
smape_pco2 = smape(y_pco2_test, y_pco2_pred)

# qabs
y_qabs_pred = model_qabs.predict(X_test).flatten()
mse_qabs = mean_squared_error(y_qabs_test, y_qabs_pred)
r2_qabs = r2_score(y_qabs_test, y_qabs_pred)
smape_qabs = smape(y_qabs_test, y_qabs_pred)

print("\n Model Performance:")
print(f"ANN-PCO2  â†’ MSE: {mse_pco2:.3f}, RÂ²: {r2_pco2:.3f}, SMAPE: {smape_pco2:.3f}")
print(f"ANN-qabs  â†’ MSE: {mse_qabs:.3f}, RÂ²: {r2_qabs:.3f}, SMAPE: {smape_qabs:.3f}")

# --- Save predictions to CSV ---
df_pco2 = pd.DataFrame({
    'Actual_PCO2': y_pco2_test,
    'Predicted_PCO2': y_pco2_pred
})
df_qabs = pd.DataFrame({
    'Actual_qabs': y_qabs_test,
    'Predicted_qabs': y_qabs_pred
})

df_pco2.to_csv("ANN_PCO2_predictions.csv", index=False)
df_qabs.to_csv("ANN_qabs_predictions.csv", index=False)

print("\n Predictions saved as:")
print("  - ANN_PCO2_predictions.csv")
print("  - ANN_qabs_predictions.csv")

files.download("ANN_PCO2_predictions.csv")
files.download("ANN_qabs_predictions.csv")

# --- Optional: Plot training curves ---
def plot_history(history, title):
    plt.figure(figsize=(6,4))
    plt.plot(history.history['loss'], label='Train loss')
    plt.plot(history.history['val_loss'], label='Validation loss')
    plt.title(title)
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    plt.show()

plot_history(history_pco2, "Training Curve: ANN-PCO2")
plot_history(history_qabs, "Training Curve: ANN-qabs")

# qabs
y_qabs_pred = model_qabs.predict(X_test).flatten()
mse_qabs = mean_squared_error(y_qabs_test, y_qabs_pred)
r2_qabs = r2_score(y_qabs_test, y_qabs_pred)
smape_qabs = smape(y_qabs_test, y_qabs_pred)

print("\nðŸ“Š Model Performance:")
print(f"ANN-PCO2  â†’ MSE: {mse_pco2:.3f}, RÂ²: {r2_pco2:.3f}, SMAPE: {smape_pco2:.3f}")
print(f"ANN-qabs  â†’ MSE: {mse_qabs:.3f}, RÂ²: {r2_qabs:.3f}, SMAPE: {smape_qabs:.3f}")

# --- Save predictions to CSV ---
df_pco2 = pd.DataFrame({
    'Actual_PCO2': y_pco2_test,
    'Predicted_PCO2': y_pco2_pred
})
df_qabs = pd.DataFrame({
    'Actual_qabs': y_qabs_test,
    'Predicted_qabs': y_qabs_pred
})

df_pco2.to_csv("ANN_PCO2_predictions.csv", index=False)
df_qabs.to_csv("ANN_qabs_predictions.csv", index=False)

print("\n Predictions saved as:")
print("  - ANN_PCO2_predictions.csv")
print("  - ANN_qabs_predictions.csv")

files.download("ANN_PCO2_predictions.csv")
files.download("ANN_qabs_predictions.csv")

