# -*- coding: utf-8 -*-
"""IMPROVED_SCORES_MODEL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZPY8NZ3qgKeFh9utoTGvGjdC1dgCveE2
"""

# ============================================================
# Improved ANN for COâ‚‚ Capture Modeling (PCOâ‚‚ & qabs)
# Based on Journal of Cleaner Production, 2025
# ============================================================

!pip install tensorflow pandas scikit-learn matplotlib

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.initializers import HeNormal
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from google.colab import files

# --- Upload dataset ---
uploaded = files.upload()
filename = list(uploaded.keys())[0]
data = pd.read_csv(filename)
print(f"âœ… Data loaded successfully: {filename}\n")
print(data.head())

# --- Prepare inputs and targets ---
X = data[['Temperature_K', 'Blending_ratio_wt_percent', 'Alpha_mol_CO2_per_mol_amine']].values
y_pco2 = data['PCO2_kPa'].values.reshape(-1,1)
y_qabs = data['qabs_kJ_per_mol_CO2'].values.reshape(-1,1)

# --- Normalize inputs and outputs ---
X_scaler = StandardScaler()
y_scaler_pco2 = StandardScaler()
y_scaler_qabs = StandardScaler()

X_scaled = X_scaler.fit_transform(X)
y_pco2_scaled = y_scaler_pco2.fit_transform(y_pco2)
y_qabs_scaled = y_scaler_qabs.fit_transform(y_qabs)

# --- Train-test split ---
X_train, X_test, y_pco2_train, y_pco2_test = train_test_split(X_scaled, y_pco2_scaled, test_size=0.15, random_state=42)
_, _, y_qabs_train, y_qabs_test = train_test_split(X_scaled, y_qabs_scaled, test_size=0.15, random_state=42)

# --- Build simplified ANN model ---
def build_ann():
    model = Sequential([
        Dense(32, activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-4), input_shape=(3,)),
        Dropout(0.2),
        Dense(16, activation='relu', kernel_initializer=HeNormal(), kernel_regularizer=l2(1e-4)),
        Dense(1)  # no activation for regression
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mse'])
    return model

# --- Train ANN for PCO2 ---
print("\nðŸš€ Training ANN for PCO2 prediction...")
model_pco2 = build_ann()
history_pco2 = model_pco2.fit(
    X_train, y_pco2_train, epochs=500, batch_size=8,
    validation_split=0.2, verbose=1,
    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)]
)

# --- Train ANN for qabs ---
print("\nðŸ”¥ Training ANN for qabs prediction...")
model_qabs = build_ann()
history_qabs = model_qabs.fit(
    X_train, y_qabs_train, epochs=500, batch_size=8,
    validation_split=0.2, verbose=1,
    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)]
)

# --- Evaluate & Predict ---
def smape(y_true, y_pred):
    return np.mean(100 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-6) / 2)

# PCO2
y_pco2_pred_scaled = model_pco2.predict(X_test)
y_pco2_pred = y_scaler_pco2.inverse_transform(y_pco2_pred_scaled)
y_pco2_true = y_scaler_pco2.inverse_transform(y_pco2_test)
mse_pco2 = mean_squared_error(y_pco2_true, y_pco2_pred)
r2_pco2 = r2_score(y_pco2_true, y_pco2_pred)
smape_pco2 = smape(y_pco2_true, y_pco2_pred)

# qabs
y_qabs_pred_scaled = model_qabs.predict(X_test)
y_qabs_pred = y_scaler_qabs.inverse_transform(y_qabs_pred_scaled)
y_qabs_true = y_scaler_qabs.inverse_transform(y_qabs_test)
mse_qabs = mean_squared_error(y_qabs_true, y_qabs_pred)
r2_qabs = r2_score(y_qabs_true, y_qabs_pred)
smape_qabs = smape(y_qabs_true, y_qabs_pred)

print("\n Model Performance:")
print(f"ANN-PCO2  â†’ MSE: {mse_pco2:.3f}, RÂ²: {r2_pco2:.3f}, SMAPE: {smape_pco2:.3f}")
print(f"ANN-qabs  â†’ MSE: {mse_qabs:.3f}, RÂ²: {r2_qabs:.3f}, SMAPE: {smape_qabs:.3f}")

# --- Save predictions to CSV ---
df_pco2 = pd.DataFrame({
    'Actual_PCO2': y_pco2_true.flatten(),
    'Predicted_PCO2': y_pco2_pred.flatten()
})
df_qabs = pd.DataFrame({
    'Actual_qabs': y_qabs_true.flatten(),
    'Predicted_qabs': y_qabs_pred.flatten()
})

df_pco2.to_csv("Improved_ANN_PCO2_predictions.csv", index=False)
df_qabs.to_csv("Improved_ANN_qabs_predictions.csv", index=False)

files.download("Improved_ANN_PCO2_predictions.csv")
files.download("Improved_ANN_qabs_predictions.csv")

# --- Plot learning curves ---
def plot_history(history, title):
    plt.figure(figsize=(6,4))
    plt.plot(history.history['loss'], label='Train loss')
    plt.plot(history.history['val_loss'], label='Validation loss')
    plt.title(title)
    plt.xlabel('Epochs')
    plt.ylabel('MSE Loss')
    plt.legend()
    plt.grid(True)
    plt.show()

plot_history(history_pco2, "Training Curve: Improved ANN - PCO2")
plot_history(history_qabs, "Training Curve: Improved ANN - qabs")